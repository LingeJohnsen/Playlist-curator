{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empirical-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# import kerastuner as kt\n",
    "# from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integrated-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-might",
   "metadata": {},
   "source": [
    "### Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinct-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(true_pos, false_pos, true_neg, false_neg):\n",
    "    conf_matrix = np.array([\n",
    "                            [true_pos, false_pos],\n",
    "                            [false_neg, true_neg]\n",
    "                           ])\n",
    "    \n",
    "    return pd.DataFrame(conf_matrix, columns=['1', '0'], index=['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriental-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_plot(model, metric):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    fig = plt.plot(model.history[metric], color='black')\n",
    "    fig = plt.plot(model.history['val_'+metric], color='blue')\n",
    "\n",
    "    plt.title('Changes in {} over training run'.format(metric))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    \n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mediterranean-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_recall(model, positives_flag=True):\n",
    "    \n",
    "    if positives_flag:\n",
    "        recall = [tp / (tp+fn) for tp, fn in zip(model.history['true_positives'], model.history['false_negatives'])]\n",
    "        val_recall = [tp / (tp+fn) for tp, fn in zip(model.history['val_true_positives'], model.history['val_false_negatives'])]\n",
    "        recall_type = 'positive'\n",
    "    else:\n",
    "        recall = [tn / (tn+fp) for tn, fp in zip(model.history['true_negatives'], model.history['false_positives'])]\n",
    "        val_recall = [tn / (tn+fp) for tn, fp in zip(model.history['val_true_negatives'], model.history['val_false_positives'])]\n",
    "        recall_type = 'negative'\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    fig = plt.plot(recall, color='black')\n",
    "    fig = plt.plot(val_recall, color='blue')\n",
    "    \n",
    "    plt.title('Changes in {} recall rate over training run.'.format(recall_type))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('{} recall rate'.format(recall_type))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_models(num_models, input_dims, compile_metrics, seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    all_models = []\n",
    "    \n",
    "    for m in range(num_models): \n",
    "        \n",
    "        num_hidden_layers = np.random.randint(1, 11)\n",
    "        all_models.append(build_model(num_hidden_layers, input_dims, compile_metrics))\n",
    "    \n",
    "    return all_models\n",
    "\n",
    "def build_layers(num_layers, input_dims):\n",
    "\n",
    "    layers = []\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        \n",
    "        num_units = np.random.randint(2, 27)\n",
    "        reg_val = 10**(-4*np.random.rand())\n",
    "        if i==0:\n",
    "            layers.append(Dense(\n",
    "                                units = num_units,\n",
    "                                input_dim = input_dims,\n",
    "                                activation = 'relu',\n",
    "                                kernel_regularizer = l2(l2=reg_val)\n",
    "                               ))\n",
    "        else:\n",
    "            layers.append(Dense(\n",
    "                                units = num_units,\n",
    "                                activation = 'relu',\n",
    "                                kernel_regularizer = l2(l2=reg_val)\n",
    "                               ))\n",
    "    reg_val = 10**(-4*np.random.rand())\n",
    "    layers.append(Dense(\n",
    "                        units = 1,\n",
    "                        activation = 'sigmoid',\n",
    "                        kernel_regularizer = l2(l2=reg_val)\n",
    "                       ))\n",
    "    return layers\n",
    "\n",
    "def build_model(num_hidden_layers, input_dims, compile_metrics):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    layers = build_layers(num_hidden_layers, input_dims)\n",
    "    for l in layers:\n",
    "        model.add(l)\n",
    "    \n",
    "    learning_rate = 10**(-4*np.random.rand())\n",
    "    model.compile(optimizer = Adam(learning_rate), loss='binary_crossentropy', metrics=[compile_metrics])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-wallace",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opened-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jazz.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diverse-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to analyze\n",
    "features = [\n",
    "            'danceability',\n",
    "            'energy',\n",
    "            'speechiness',\n",
    "            'acousticness',\n",
    "            'instrumentalness',\n",
    "            'liveness',\n",
    "            'valence',\n",
    "            'num_samples',\n",
    "            'end_of_fade_in',\n",
    "            'loudness',\n",
    "            'tempo',\n",
    "            'key',\n",
    "            'mode',\n",
    "            'bars_num',\n",
    "            'bars_duration_var',\n",
    "            'beats_duration_var',\n",
    "            'sections_num',\n",
    "            'sections_duration_mean',\n",
    "            'sections_duration_var',\n",
    "            'loudness_var',\n",
    "            'tempo_var',\n",
    "            'key_var',\n",
    "            'mode_var',\n",
    "            'segments_duration_var',\n",
    "            'segments_duration_mean',\n",
    "            'pitches_mean',\n",
    "            'pitches_var',\n",
    "            'timbre_mean',\n",
    "            'timbre_var',\n",
    "            'tatums_duration_var'\n",
    "           ]\n",
    "\n",
    "df = df[features+['label']]\n",
    "\n",
    "# Shuffle data to ungroup class rows\n",
    "df = df.sample(frac=1, random_state=12).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boolean-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-endorsement",
   "metadata": {},
   "source": [
    "Split dataset into training, validation, and test. 60/20/20 gives ~936 positive training samples, and ~312 each of positive validation and test samples. Quite small, but hopefully big enough to be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "basic-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].copy()\n",
    "Y = df['label'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    X,\n",
    "                                                    Y, \n",
    "                                                    stratify = Y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-wheel",
   "metadata": {},
   "source": [
    "# Start building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rational-possession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First fit how to scale data for the model\n",
    "pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "scale_model = pipeline.fit(X_train)\n",
    "X_train = scale_model.transform(X_train)\n",
    "X_test = scale_model.transform(X_test)\n",
    "\n",
    "# Save for later use\n",
    "dump(scale_model, 'scaler.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "popular-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alexander\\anaconda3\\envs\\playlistenv\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0479s). Check your callbacks.\n",
      "Average validation loss for model  1 :  1.247082142829895\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.5313s). Check your callbacks.\n",
      "Average validation loss for model  2 :  0.7802540791034699\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.8818s). Check your callbacks.\n",
      "Average validation loss for model  3 :  0.7538687134981156\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 1.8092s). Check your callbacks.\n",
      "Average validation loss for model  4 :  0.711441454410553\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 2.2161s). Check your callbacks.\n",
      "Average validation loss for model  5 :  0.6908894851207733\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.7699s). Check your callbacks.\n",
      "Average validation loss for model  6 :  0.7697943080663681\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.7799s). Check your callbacks.\n",
      "Average validation loss for model  7 :  1.1231872308254243\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.0577s). Check your callbacks.\n",
      "Average validation loss for model  8 :  0.549254743039608\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 2.0109s). Check your callbacks.\n",
      "Average validation loss for model  9 :  0.6144829293489457\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 2.1378s). Check your callbacks.\n",
      "Average validation loss for model  10 :  0.6871076166629791\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.9847s). Check your callbacks.\n",
      "Average validation loss for model  11 :  0.5356809813976288\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.4889s). Check your callbacks.\n",
      "Average validation loss for model  12 :  0.7370461231470108\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.2503s). Check your callbacks.\n",
      "Average validation loss for model  13 :  0.9959176428318024\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 1.2039s). Check your callbacks.\n",
      "Average validation loss for model  14 :  0.5383603849411011\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.3099s). Check your callbacks.\n",
      "Average validation loss for model  15 :  0.8163906596899032\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 2.3672s). Check your callbacks.\n",
      "Average validation loss for model  16 :  0.5408744995594025\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 2.6733s). Check your callbacks.\n",
      "Average validation loss for model  17 :  0.6939545936584472\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.1664s). Check your callbacks.\n",
      "Average validation loss for model  18 :  0.5431868675947189\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 2.4954s). Check your callbacks.\n",
      "Average validation loss for model  19 :  0.5843731558322907\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 1.0945s). Check your callbacks.\n",
      "Average validation loss for model  20 :  1.2883152837753296\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.1063s). Check your callbacks.\n",
      "Average validation loss for model  21 :  0.5484917083382607\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 2.8144s). Check your callbacks.\n",
      "Average validation loss for model  22 :  0.6005459662675857\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 1.2612s). Check your callbacks.\n",
      "Average validation loss for model  23 :  0.6869194117784501\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 3.0046s). Check your callbacks.\n",
      "Average validation loss for model  24 :  0.7093826110363006\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 1.3363s). Check your callbacks.\n",
      "Average validation loss for model  25 :  0.7509989014863968\n"
     ]
    }
   ],
   "source": [
    "logdir = 'logs/scalars/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "metrics = [\n",
    "           tfk.metrics.Precision(),\n",
    "           tfk.metrics.TruePositives(),\n",
    "           tfk.metrics.TrueNegatives(),\n",
    "           tfk.metrics.FalsePositives(),\n",
    "           tfk.metrics.FalseNegatives(),\n",
    "           tfk.metrics.AUC(curve='PR')\n",
    "          ]\n",
    "\n",
    "models = random_search_models(num_models=25, input_dims=len(features), compile_metrics=metrics, seed=42)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    training_history = model.fit(\n",
    "                                 X_train,\n",
    "                                 y_train,\n",
    "                                 batch_size = 128,\n",
    "                                 verbose = 0,\n",
    "                                 epochs = 500,\n",
    "                                 validation_split = 0.2,\n",
    "                                 callbacks=[callbacks.TensorBoard(log_dir=logdir+'-'+str(i))],\n",
    "                                )\n",
    "    \n",
    "    print('Average validation loss for model ', str(i+1), ': ', np.average(training_history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "centered-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 252), started 0:15:12 ago. (Use '!kill 252' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dbd10861b4de18c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dbd10861b4de18c3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "informational-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a dynamic naming schedule that's not too long (datetimes make the filename too long for Windows)\n",
    "# kt_dir = os.path.normpath('./logs/005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "clear-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = RandomSearch(\n",
    "#                      build_model,\n",
    "#                      objective = kt.Objective('val_loss', direction='min'),\n",
    "#                      max_trials = 25,\n",
    "#                      executions_per_trial = 3,\n",
    "#                      directory = os.path.normpath(kt_dir),\n",
    "#                      project_name = 'jazzy-curator'\n",
    "#                     )\n",
    "\n",
    "# tuner.search(\n",
    "#               X_train, \n",
    "#               y_train,\n",
    "#               epochs = 500,\n",
    "#               validation_split = 0.2,\n",
    "#               batch_size = 128,\n",
    "#               callbacks = [callbacks.TensorBoard(kt_dir)],\n",
    "#               shuffle = True\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nutritional-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = tuner.get_best_models(num_models=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "frozen-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.oracle.get_best_trials()[0].trial_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promising-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-budget",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-column",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "capital-shareware",
   "metadata": {},
   "source": [
    "# Evaluate model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "external-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_plot(models[0], 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "furnished-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_plot(jazz_model, 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "finnish-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_plot(jazz_model, 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tough-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_recall(jazz_model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "threatened-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_recall(jazz_model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "overhead-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = jazz_model.history['loss'][-1]\n",
    "# val_loss = jazz_model.history['val_loss'][-1]\n",
    "# print('Loss for training set is {}, while loss for validation set is {}. This gives a difference of {}'\\\n",
    "#       .format(\n",
    "#               round(loss,4),\n",
    "#               round(val_loss,4), \n",
    "#               round(val_loss-loss, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "entitled-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc = jazz_model.history['auc'][-1]\n",
    "# val_auc = jazz_model.history['val_auc'][-1]\n",
    "# print('AUC for training set is {}, while AUC for validation set is {}. This gives a difference of {}'\\\n",
    "#       .format(round(auc, 2), round(val_auc, 2), round(auc-val_auc,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "everyday-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_positives_val = jazz_model.history['val_true_positives'][-1]\n",
    "# false_positives_val = jazz_model.history['val_false_positives'][-1]\n",
    "# true_negatives_val = jazz_model.history['val_true_negatives'][-1]\n",
    "# false_negatives_val = jazz_model.history['val_false_negatives'][-1]\n",
    "\n",
    "# val_conf_matrix = get_confusion_matrix(\n",
    "#                                        true_positives_val,\n",
    "#                                        false_positives_val,\n",
    "#                                        true_negatives_val,\n",
    "#                                        false_negatives_val\n",
    "#                                        )\n",
    "\n",
    "# print('Confusion_matrix:\\n{}'.format(val_conf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adaptive-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('True recall rate is {}'\\\n",
    "#       .format(round(val_conf_matrix.loc['1', '1']/(val_conf_matrix.loc['1', '1']+val_conf_matrix.loc['0', '1']),2)))\n",
    "# print('Precision is {}'.format(jazz_model.history['val_precision'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-munich",
   "metadata": {},
   "source": [
    "Looks very promising on validation set! Let's check test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cooked-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_test, precision_test, true_positives_test, true_negatives_test, false_positives_test, false_negatives_test, auc_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "skilled-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('AUC for test set is {}.'.format(round(auc_test,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "choice-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = get_confusion_matrix(\n",
    "#                                         true_positives_test,\n",
    "#                                         false_positives_test,\n",
    "#                                         true_negatives_test,\n",
    "#                                         false_negatives_test\n",
    "#                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "about-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ordered-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#       'True recall rate is {}'\\\n",
    "#       .format(round(\n",
    "#                     confusion_matrix.loc['1', '1']/\n",
    "#                     (confusion_matrix.loc['1', '1']+confusion_matrix.loc['0', '1']),\n",
    "#                     2\n",
    "#                    )\n",
    "#              )\n",
    "#      )\n",
    "# print('Precision is {}'.format(round(precision_test,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-cherry",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "determined-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('jazz_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-canadian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playlistenv",
   "language": "python",
   "name": "playlistenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
